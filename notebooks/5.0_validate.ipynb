{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import v√† load model\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model v√† label encoder\n",
    "model = tf.keras.models.load_model('../data/models/mel_final_model.keras')\n",
    "with open('../data/models/mel_label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: H√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
    "def extract_mel_spectrogram(audio_path, n_mels=128, n_fft=2048, hop_length=128):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # Extract mel spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=y, \n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        fmin=20,\n",
    "        fmax=sr/2,\n",
    "        power=2.0\n",
    "    )\n",
    "    \n",
    "    # Convert to log scale (dB)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Chu·∫©n h√≥a v·ªÅ kho·∫£ng [0,1]\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())\n",
    "    \n",
    "    # Resize v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh (128, 32)\n",
    "    mel_spec_norm = tf.image.resize(mel_spec_norm[..., np.newaxis], (128, 32))\n",
    "    mel_spec_norm = mel_spec_norm.numpy()\n",
    "    mel_spec_norm = mel_spec_norm[..., 0]\n",
    "    \n",
    "    return mel_spec_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 3: H√†m d·ª± ƒëo√°n\n",
    "def predict_command(audio_path):\n",
    "    # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
    "    mel_features = extract_mel_spectrogram(audio_path)\n",
    "    \n",
    "    # Reshape cho model (1, 128, 32, 1)\n",
    "    mel_features = mel_features.reshape(1, 128, 32, 1)\n",
    "    \n",
    "    # D·ª± ƒëo√°n\n",
    "    predictions = model.predict(mel_features, verbose=0)\n",
    "    \n",
    "    # √Åp d·ª•ng softmax ƒë·ªÉ c√≥ x√°c su·∫•t\n",
    "    predictions = tf.nn.softmax(predictions)\n",
    "    predictions = predictions.numpy()\n",
    "    \n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    # Chuy·ªÉn ƒë·ªïi label\n",
    "    predicted_command = le.inverse_transform([predicted_class])[0]\n",
    "    \n",
    "    return predicted_command, confidence, mel_features, predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = '../data/processed'\n",
    "test_files = []  # Global variable for test files\n",
    "\n",
    "def get_all_audio_files(directory):\n",
    "    audio_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    return audio_files\n",
    "\n",
    "def evaluate_random_samples(predict_fn, num_samples=5):\n",
    "    global test_files\n",
    "    audio_files = get_all_audio_files(PROCESSED_DIR)\n",
    "\n",
    "    if len(audio_files) < num_samples:\n",
    "        raise ValueError(f\"Kh√¥ng ƒë·ªß file audio ƒë·ªÉ l·∫•y {num_samples} m·∫´u (ch·ªâ c√≥ {len(audio_files)} file)\")\n",
    "\n",
    "    test_files = random.sample(audio_files, num_samples)\n",
    "    correct = 0\n",
    "\n",
    "    fig = plt.figure(figsize=(15, num_samples * 2))\n",
    "\n",
    "    # ƒê·∫∑t ti√™u ƒë·ªÅ 2 c·ªôt 1 l·∫ßn duy nh·∫•t\n",
    "    fig.text(0.25, 0.92, \"Mel Spectrogram\", fontsize=16, ha='center')\n",
    "    fig.text(0.75, 0.92, \"Waveform\", fontsize=16, ha='center')\n",
    "\n",
    "    for i, audio_path in enumerate(test_files):\n",
    "        true_label = os.path.basename(os.path.dirname(audio_path))\n",
    "        pred_label, confidence, mel_spec, _ = predict_fn(audio_path)\n",
    "\n",
    "        # C·ªôt 1: Mel spectrogram\n",
    "        plt.subplot(num_samples, 2, i * 2 + 1)\n",
    "        plt.imshow(mel_spec[0, :, :, 0], aspect='auto', origin='lower', cmap='viridis')\n",
    "        plt.title(f\"True: {true_label} | Pred: {pred_label} ({confidence:.2f})\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Mel Bins\")\n",
    "\n",
    "        # C·ªôt 2: Waveform\n",
    "        plt.subplot(num_samples, 2, i * 2 + 2)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        times = np.linspace(0, len(y) / sr, len(y))\n",
    "        plt.plot(times, y)\n",
    "        plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = correct / num_samples\n",
    "    print(f\"\\n‚úÖ Accuracy: {correct}/{num_samples} ({accuracy:.2%})\")\n",
    "\n",
    "evaluate_random_samples(predict_command, num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: In k·∫øt qu·∫£ chi ti·∫øt\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(\"=\" * 60)\n",
    "for audio_path in test_files:\n",
    "    true_command = os.path.basename(os.path.dirname(audio_path))\n",
    "    predicted_command, confidence, _, all_probs = predict_command(audio_path)\n",
    "    \n",
    "    print(f\"Audio file: {os.path.basename(audio_path)}\")\n",
    "    print(f\"True label: {true_command}\")\n",
    "    print(f\"Prediction: {predicted_command}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    \n",
    "    print(\"\\nProbabilities for each class:\")\n",
    "    # Sort probabilities in descending order\n",
    "    sorted_probs = sorted(enumerate(all_probs), key=lambda x: x[1], reverse=True)\n",
    "    for i, prob in sorted_probs:\n",
    "        command = le.inverse_transform([i])[0]\n",
    "        print(f\"{command:15s}: {prob:.2%}\")\n",
    "    \n",
    "    print(f\"\\nResult: {'‚úì Correct' if true_command == predicted_command else '‚úó Wrong'}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test cho m·ªôt file c·ª• th·ªÉ\n",
    "def evaluate_single_file(audio_path, predict_fn):\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise ValueError(f\"Kh√¥ng t√¨m th·∫•y file: {audio_path}\")\n",
    "    \n",
    "    # T·∫°o figure v·ªõi 2 subplot\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # ƒê·∫∑t ti√™u ƒë·ªÅ 2 c·ªôt\n",
    "    fig.text(0.25, 0.92, \"Mel Spectrogram\", fontsize=16, ha='center')\n",
    "    fig.text(0.75, 0.92, \"Waveform\", fontsize=16, ha='center')\n",
    "    \n",
    "    # L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "    true_label = os.path.basename(os.path.dirname(audio_path))\n",
    "    pred_label, confidence, mel_spec, all_probs = predict_fn(audio_path)\n",
    "    \n",
    "    # C·ªôt 1: Mel spectrogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(mel_spec[0, :, :, 0], aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.title(f\"True: {true_label} | Pred: {pred_label} ({confidence:.2f})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Mel Bins\")\n",
    "    \n",
    "    # C·ªôt 2: Waveform\n",
    "    plt.subplot(1, 2, 2)\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    times = np.linspace(0, len(y) / sr, len(y))\n",
    "    plt.plot(times, y)\n",
    "    plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüéµ Playing audio...\")\n",
    "    from IPython.display import Audio\n",
    "    display(Audio(audio_path))\n",
    "    \n",
    "    # In k·∫øt qu·∫£ chi ti·∫øt\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Audio file: {os.path.basename(audio_path)}\")\n",
    "    print(f\"True label: {true_label}\")\n",
    "    print(f\"Prediction: {pred_label}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    \n",
    "    print(\"\\nProbabilities for each class:\")\n",
    "    # Sort probabilities in descending order\n",
    "    sorted_probs = sorted(enumerate(all_probs), key=lambda x: x[1], reverse=True)\n",
    "    for i, prob in sorted_probs:\n",
    "        command = le.inverse_transform([i])[0]\n",
    "        print(f\"{command:15s}: {prob:.2%}\")\n",
    "    \n",
    "    print(f\"\\nResult: {'‚úì Correct' if true_label == pred_label else '‚úó Wrong'}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# S·ª≠ d·ª•ng: Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n file ·ªü ƒë√¢y\n",
    "audio_path = \"../data/processed/bat_den/bat_den_speaker04_015.wav\"  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y\n",
    "evaluate_single_file(audio_path, predict_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
