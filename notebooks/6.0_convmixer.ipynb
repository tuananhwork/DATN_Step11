{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: AudioTransform class for data augmentation\n",
    "class AudioTransform:\n",
    "    def __init__(self, time_mask_prob=0.5, freq_mask_prob=0.5, time_stretch_prob=0.5):\n",
    "        self.time_mask_prob = time_mask_prob\n",
    "        self.freq_mask_prob = freq_mask_prob\n",
    "        self.time_stretch_prob = time_stretch_prob\n",
    "        \n",
    "    def time_mask(self, mel_spec, max_mask_length=0.1):\n",
    "        \"\"\"Áp dụng time masking cho mel spectrogram\"\"\"\n",
    "        if random.random() < self.time_mask_prob:\n",
    "            # Lấy shape của mel spectrogram\n",
    "            if len(mel_spec.shape) == 3:  # Nếu có channel dimension\n",
    "                _, n_mels, n_time = mel_spec.shape\n",
    "                mel_spec = mel_spec[0]  # Lấy channel đầu tiên\n",
    "            else:\n",
    "                n_mels, n_time = mel_spec.shape\n",
    "                \n",
    "            mask_length = int(n_time * max_mask_length)\n",
    "            mask_start = random.randint(0, n_time - mask_length)\n",
    "            mel_spec[:, mask_start:mask_start + mask_length] = 0\n",
    "            \n",
    "            if len(mel_spec.shape) == 2:  # Nếu ban đầu có channel dimension\n",
    "                mel_spec = np.expand_dims(mel_spec, axis=0)\n",
    "        return mel_spec\n",
    "    \n",
    "    def freq_mask(self, mel_spec, max_mask_length=0.1):\n",
    "        \"\"\"Áp dụng frequency masking cho mel spectrogram\"\"\"\n",
    "        if random.random() < self.freq_mask_prob:\n",
    "            # Lấy shape của mel spectrogram\n",
    "            if len(mel_spec.shape) == 3:  # Nếu có channel dimension\n",
    "                _, n_mels, n_time = mel_spec.shape\n",
    "                mel_spec = mel_spec[0]  # Lấy channel đầu tiên\n",
    "            else:\n",
    "                n_mels, n_time = mel_spec.shape\n",
    "                \n",
    "            mask_length = int(n_mels * max_mask_length)\n",
    "            mask_start = random.randint(0, n_mels - mask_length)\n",
    "            mel_spec[mask_start:mask_start + mask_length, :] = 0\n",
    "            \n",
    "            if len(mel_spec.shape) == 2:  # Nếu ban đầu có channel dimension\n",
    "                mel_spec = np.expand_dims(mel_spec, axis=0)\n",
    "        return mel_spec\n",
    "    \n",
    "    def time_stretch(self, mel_spec, stretch_range=(0.8, 1.2)):\n",
    "        \"\"\"Áp dụng time stretching cho mel spectrogram\"\"\"\n",
    "        if random.random() < self.time_stretch_prob:\n",
    "            # Lấy shape của mel spectrogram\n",
    "            if len(mel_spec.shape) == 3:  # Nếu có channel dimension\n",
    "                _, n_mels, n_time = mel_spec.shape\n",
    "                mel_spec = mel_spec[0]  # Lấy channel đầu tiên\n",
    "            else:\n",
    "                n_mels, n_time = mel_spec.shape\n",
    "                \n",
    "            stretch_factor = random.uniform(*stretch_range)\n",
    "            new_time = int(n_time * stretch_factor)\n",
    "            stretched = np.zeros((n_mels, new_time))\n",
    "            \n",
    "            for i in range(n_mels):\n",
    "                stretched[i] = np.interp(\n",
    "                    np.linspace(0, n_time, new_time),\n",
    "                    np.arange(n_time),\n",
    "                    mel_spec[i]\n",
    "                )\n",
    "            \n",
    "            # Resize về kích thước ban đầu\n",
    "            if stretch_factor > 1:\n",
    "                # Nếu stretch > 1, cắt bớt\n",
    "                mel_spec = stretched[:, :n_time]\n",
    "            else:\n",
    "                # Nếu stretch < 1, padding\n",
    "                mel_spec = np.pad(stretched, ((0, 0), (0, n_time - new_time)))\n",
    "                \n",
    "            if len(mel_spec.shape) == 2:  # Nếu ban đầu có channel dimension\n",
    "                mel_spec = np.expand_dims(mel_spec, axis=0)\n",
    "                \n",
    "        return mel_spec\n",
    "    \n",
    "    def __call__(self, mel_spec):\n",
    "        \"\"\"Áp dụng tất cả các augmentation\"\"\"\n",
    "        mel_spec = self.time_mask(mel_spec)\n",
    "        mel_spec = self.freq_mask(mel_spec)\n",
    "        mel_spec = self.time_stretch(mel_spec)\n",
    "        return mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: LoadData class for dataset handling\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        # Lọc bỏ metadata.csv khỏi danh sách classes\n",
    "        self.classes = [d for d in sorted(os.listdir(data_dir)) \n",
    "                       if os.path.isdir(os.path.join(data_dir, d))]\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.npy'):  # Đặc trưng mel spectrogram\n",
    "                    self.samples.append((os.path.join(class_dir, file_name), self.class_to_idx[class_name]))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        features = np.load(file_path)\n",
    "        \n",
    "        if len(features.shape) == 2:\n",
    "            features = np.expand_dims(features, axis=0)\n",
    "            \n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "            \n",
    "        return torch.FloatTensor(features), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create datasets and dataloaders\n",
    "# Đọc metadata để chia train/test/val\n",
    "metadata = pd.read_csv('../data/features/mel/metadata.csv')\n",
    "\n",
    "# Tạo dataset với đường dẫn đầy đủ\n",
    "base_dir = '../data/features/mel'\n",
    "\n",
    "# Tạo transform cho augmentation\n",
    "train_transform = AudioTransform(\n",
    "    time_mask_prob=0.5,\n",
    "    freq_mask_prob=0.5,\n",
    "    time_stretch_prob=0.5\n",
    ")\n",
    "\n",
    "# Tạo dataset với augmentation cho training\n",
    "full_ds = LoadData(base_dir, transform=train_transform)\n",
    "\n",
    "# Chia dataset thành train (70%), val (15%), test (15%)\n",
    "train_size = int(0.7 * len(full_ds))\n",
    "val_size = int(0.15 * len(full_ds))\n",
    "test_size = len(full_ds) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = torch.utils.data.random_split(\n",
    "    full_ds, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # Đảm bảo tính tái lập\n",
    ")\n",
    "\n",
    "# Tạo DataLoader\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0),\n",
    "    'val': DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=0),\n",
    "    'test': DataLoader(test_ds, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=0),\n",
    "}\n",
    "\n",
    "# In thông tin về dataset\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of validation samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")\n",
    "print(f\"Number of classes: {len(full_ds.classes)}\")\n",
    "print(f\"Classes: {full_ds.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL]\n",
    "# Tính số lượng samples cho mỗi class\n",
    "class_counts = {}\n",
    "for class_name in full_ds.classes:\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    class_counts[class_name] = len([f for f in os.listdir(class_dir) if f.endswith('.npy')])\n",
    "\n",
    "# Vẽ bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Distribution of Classes in Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In thông tin chi tiết\n",
    "print(\"\\nClass Distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL]\n",
    "def plot_sample_spectrograms(dataset, num_samples=3):\n",
    "    plt.figure(figsize=(15, 4*len(dataset.classes)))\n",
    "    \n",
    "    for class_idx, class_name in enumerate(dataset.classes):\n",
    "        # Lấy indices của class hiện tại\n",
    "        class_indices = [i for i, (_, label) in enumerate(dataset.samples) if label == class_idx]\n",
    "        \n",
    "        # Lấy ngẫu nhiên num_samples mẫu\n",
    "        sample_indices = random.sample(class_indices, min(num_samples, len(class_indices)))\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            plt.subplot(len(dataset.classes), num_samples, class_idx*num_samples + i + 1)\n",
    "            mel_spec, _ = dataset[idx]\n",
    "            plt.imshow(mel_spec[0], aspect='auto', origin='lower')\n",
    "            plt.title(f'{class_name} - Sample {i+1}')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để hiển thị\n",
    "plot_sample_spectrograms(full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ConvMixer model definition\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "def ConvMixer(dim, depth, kernel_size=9, patch_size=7, n_classes=12):  # Sửa thành 12 classes\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size),  # Input channel = 1 cho mel spectrogram\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "            Residual(nn.Sequential(\n",
    "                nn.Conv2d(dim, dim, kernel_size=kernel_size, groups=dim, padding=\"same\"),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "            )),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(dim)\n",
    "        ) for i in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Initialize model and training parameters\n",
    "# Khởi tạo mô hình\n",
    "model = ConvMixer(dim=256, depth=8, n_classes=12)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Kiểm tra và chuyển model lên GPU nếu có\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Các tham số training\n",
    "num_epochs = 20\n",
    "patience = 5  # Số epoch chờ đợi trước khi early stopping\n",
    "min_delta = 0.02  # Ngưỡng cải thiện tối thiểu\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.2,  # Giảm learning rate mạnh hơn\n",
    "    patience=3,\n",
    "    min_lr=1e-6  # Learning rate tối thiểu\n",
    ")\n",
    "\n",
    "# In thông tin về model và device\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training loop\n",
    "# Khởi tạo các list để lưu metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Tính và lưu training loss\n",
    "    epoch_train_loss = running_loss / len(dataloaders['train'])\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_train_loss:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Tính và lưu validation metrics\n",
    "    epoch_val_loss = val_loss / len(dataloaders['val'])\n",
    "    val_acc = 100 * correct / total\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f'Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "    # Cập nhật learning rate\n",
    "    scheduler.step(val_acc)\n",
    "    print(f'Current learning rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc + min_delta:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        # Lưu model tốt nhất\n",
    "        torch.save(model.state_dict(), '../data/models/audio_classifier_best.pth')\n",
    "        print(f'New best model saved! Validation Accuracy: {val_acc:.2f}%')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'No improvement for {patience_counter} epochs')\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "        break\n",
    "\n",
    "# Lưu model cuối cùng\n",
    "torch.save(model.state_dict(), '../data/models/audio_classifier_final.pth')\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL]\n",
    "# Lưu learning rate history\n",
    "lr_history = []\n",
    "for param_group in optimizer.param_groups:\n",
    "    lr_history.append(param_group['lr'])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(lr_history, marker='o')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')  # Log scale để dễ nhìn sự thay đổi\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, marker='o', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, marker='o', label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate on test set and plot confusion matrix\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"Đánh giá model trên tập test\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            \n",
    "    test_acc = 100 * correct / total\n",
    "    avg_loss = test_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, test_acc, all_labels, all_predictions\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Vẽ confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    cm_display = metrics.ConfusionMatrixDisplay(\n",
    "        confusion_matrix=confusion_matrix,\n",
    "        display_labels=class_names\n",
    "    )\n",
    "    \n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load model tốt nhất\n",
    "model.load_state_dict(torch.load('../data/models/audio_classifier_best.pth'))\n",
    "\n",
    "# Đánh giá model\n",
    "test_loss, test_acc, all_labels, all_predictions = evaluate_model(\n",
    "    model, dataloaders['test'], criterion, device\n",
    ")\n",
    "\n",
    "# In kết quả\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "\n",
    "# Vẽ confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "confusion_matrix = metrics.confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Vẽ heatmap\n",
    "plt.imshow(confusion_matrix, cmap='YlOrRd')\n",
    "plt.colorbar()\n",
    "\n",
    "# Thêm giá trị vào từng ô\n",
    "for i in range(len(full_ds.classes)):\n",
    "    for j in range(len(full_ds.classes)):\n",
    "        plt.text(j, i, f'{confusion_matrix[i, j]}',\n",
    "                ha='center', va='center')\n",
    "\n",
    "plt.title('Confusion Matrix', pad=20, fontsize=14)\n",
    "plt.xlabel('Predicted Label', labelpad=10)\n",
    "plt.ylabel('True Label', labelpad=10)\n",
    "\n",
    "# Thêm labels\n",
    "plt.xticks(range(len(full_ds.classes)), full_ds.classes, rotation=90, ha='right')\n",
    "plt.yticks(range(len(full_ds.classes)), full_ds.classes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(metrics.classification_report(all_labels, all_predictions, target_names=full_ds.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL]\n",
    "def plot_class_accuracy(y_true, y_pred, class_names):\n",
    "    # Tính accuracy cho từng class\n",
    "    class_accuracies = []\n",
    "    for i in range(len(class_names)):\n",
    "        mask = (y_true == i)\n",
    "        if sum(mask) > 0:\n",
    "            accuracy = np.mean(y_pred[mask] == y_true[mask])\n",
    "            class_accuracies.append(accuracy)\n",
    "        else:\n",
    "            class_accuracies.append(0)\n",
    "    \n",
    "    # Vẽ bar plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(class_names, class_accuracies)\n",
    "    plt.title('Accuracy per Class')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Thêm giá trị accuracy lên mỗi bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2%}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để hiển thị\n",
    "plot_class_accuracy(np.array(all_labels), np.array(all_predictions), full_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL]\n",
    "def plot_metrics(y_true, y_pred, class_names):\n",
    "    # Tính precision, recall, f1-score cho từng class\n",
    "    precision = metrics.precision_score(y_true, y_pred, average=None)\n",
    "    recall = metrics.recall_score(y_true, y_pred, average=None)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Vẽ grouped bar chart\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x - width, precision, width, label='Precision')\n",
    "    plt.bar(x, recall, width, label='Recall')\n",
    "    plt.bar(x + width, f1, width, label='F1-score')\n",
    "    \n",
    "    plt.title('Metrics per Class')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(x, class_names, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để hiển thị\n",
    "plot_metrics(np.array(all_labels), np.array(all_predictions), full_ds.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
