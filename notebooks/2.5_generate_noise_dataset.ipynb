{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2.5 - Tạo tập dữ liệu nhiễu nền\n",
    "\n",
    "## Cell 1: Tạo tập dữ liệu nhiễu nền\n",
    "Cell này thực hiện việc tạo tập dữ liệu nhiễu nền cho lớp \"unknown\":\n",
    "- Sử dụng class AudioPreprocessor từ notebook 2.0\n",
    "- Đọc các file âm thanh nhiễu nền từ thư mục bg_noise\n",
    "- Xử lý và tạo 150 file nhiễu nền mới:\n",
    "  - Mỗi file dài 1 giây\n",
    "  - Lấy ngẫu nhiên từ các file nhiễu nền gốc\n",
    "  - Chuẩn hóa âm thanh\n",
    "  - Lưu vào thư mục processed/unknown\n",
    "\n",
    "Quy trình xử lý:\n",
    "1. Đọc tất cả file nhiễu nền từ thư mục bg_noise\n",
    "2. Với mỗi file:\n",
    "   - Tải và chuyển đổi về 16kHz\n",
    "   - Lấy ngẫu nhiên 1 đoạn 1 giây\n",
    "   - Chuẩn hóa âm thanh\n",
    "3. Nếu số lượng đoạn chưa đủ 150:\n",
    "   - Lặp lại quá trình trên với các file ngẫu nhiên\n",
    "4. Lưu tất cả các đoạn thành file WAV riêng biệt\n",
    "\n",
    "Mục đích của notebook này là:\n",
    "1. Tạo tập dữ liệu nhiễu nền cho lớp \"unknown\"\n",
    "2. Đảm bảo tính đa dạng của dữ liệu nhiễu\n",
    "3. Chuẩn hóa định dạng và chất lượng âm thanh\n",
    "4. Chuẩn bị dữ liệu cho quá trình huấn luyện mô hình phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing background files: 100%|██████████| 3/3 [00:00<00:00,  3.99it/s]\n",
      "Saving unknown segments: 100%|██████████| 150/150 [00:00<00:00, 28108.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 150 file noise in ../data/processed/unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import noisereduce as nr\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AudioPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.vad = webrtcvad.Vad(2)\n",
    "        self.target_sr = 16000\n",
    "        self.frame_duration_ms = 30\n",
    "        \n",
    "    def load_audio(self, input_path):\n",
    "        \"\"\"Load and convert audio to mono 16kHz\"\"\"\n",
    "        audio = AudioSegment.from_wav(input_path).set_channels(1).set_frame_rate(self.target_sr)\n",
    "        raw_audio = np.array(audio.get_array_of_samples())\n",
    "        rate = audio.frame_rate\n",
    "        return raw_audio, rate\n",
    "        \n",
    "    def denoise(self, audio, sr):\n",
    "        \"\"\"Apply noise reduction\"\"\"\n",
    "        denoised = nr.reduce_noise(y=audio.astype(np.float32), sr=sr)\n",
    "        if sr != self.target_sr:\n",
    "            denoised = librosa.resample(denoised, orig_sr=sr, target_sr=self.target_sr)\n",
    "        return denoised, self.target_sr\n",
    "        \n",
    "    def apply_vad(self, audio, sr):\n",
    "        \"\"\"Apply Voice Activity Detection\"\"\"\n",
    "        frame_length = int(sr * self.frame_duration_ms / 1000)\n",
    "        frames = [audio[i:i+frame_length] for i in range(0, len(audio) - frame_length, frame_length)]\n",
    "\n",
    "        def is_speech(frame):\n",
    "            int16_frame = (frame * 32768).astype(np.int16)\n",
    "            return self.vad.is_speech(int16_frame.tobytes(), sr)\n",
    "\n",
    "        flags = [is_speech(frame) for frame in frames]\n",
    "        speech_mask = np.repeat(flags, frame_length)\n",
    "        speech_mask = np.pad(speech_mask, (0, len(audio) - len(speech_mask)), mode='constant')\n",
    "        return audio * speech_mask\n",
    "        \n",
    "    def normalize_audio(self, audio):\n",
    "        \"\"\"Apply peak normalization\"\"\"\n",
    "        max_val = np.max(np.abs(audio))\n",
    "        if max_val > 0:\n",
    "            audio = audio / max_val * 0.99\n",
    "        return (audio * 32767).astype(np.int16)\n",
    "\n",
    "# Configuration\n",
    "# background_noise_dir = '../data/_background_noise_'\n",
    "background_noise_dir = '../data/bg_noise'\n",
    "output_dir = '../data/processed/unknown'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Number of files to generate\n",
    "num_output_files = 150\n",
    "\n",
    "# Initialize preprocessor\n",
    "processor = AudioPreprocessor()\n",
    "\n",
    "# List of background noise files\n",
    "background_files = [f for f in os.listdir(background_noise_dir) if f.endswith('.wav')]\n",
    "\n",
    "# Read and process all background audio\n",
    "background_segments = []\n",
    "for fname in tqdm(background_files, desc=\"Processing background files\"):\n",
    "    path = os.path.join(background_noise_dir, fname)\n",
    "    samples, sr = librosa.load(path, sr=16000)\n",
    "    \n",
    "    # Only take a random 1s segment from each file\n",
    "    if len(samples) >= sr:  # Make sure file is at least 1s long\n",
    "        # Choose random start position\n",
    "        max_start = len(samples) - sr\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "        segment = samples[start_idx:start_idx + sr]\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        segment = processor.normalize_audio(segment)\n",
    "        background_segments.append(segment)\n",
    "\n",
    "# If number of segments is less than num_output_files, repeat until enough\n",
    "while len(background_segments) < num_output_files:\n",
    "    # Randomly select a file\n",
    "    fname = np.random.choice(background_files)\n",
    "    path = os.path.join(background_noise_dir, fname)\n",
    "    samples, sr = librosa.load(path, sr=16000)\n",
    "    \n",
    "    if len(samples) >= sr:\n",
    "        max_start = len(samples) - sr\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "        segment = samples[start_idx:start_idx + sr]\n",
    "        segment = processor.normalize_audio(segment)\n",
    "        background_segments.append(segment)\n",
    "\n",
    "# Write to files\n",
    "for idx, segment in enumerate(tqdm(background_segments, desc=\"Saving unknown segments\")):\n",
    "    output_path = os.path.join(output_dir, f\"noise_{idx}.wav\")\n",
    "    wavfile.write(output_path, processor.target_sr, segment)\n",
    "\n",
    "print(f\"Created {len(background_segments)} file noise in {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
